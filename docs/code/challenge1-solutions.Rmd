---
title: "Challenge 1: Descriptive Text Analysis"
author: Pablo Barbera
date: "July 2, 2018"
output: html_document
---

This will be the first coding challenge of the course. The purpose of these exercises is for you to practice what we just went over in the guided coding session. You will have to write R code in the chunks within this RMarkdown file in order to answer each of the questions.

We will start with a dataset that contains slightly over 25,000 tweets published by the 4 leading candidates in the 2016 Presidential Primary Elections in the US (Cruz, Trump, Clinton, Sanders). Read the dataset into R and then use the `str` or `head` functions to get a sense of the variables that this dataset contains.

```{r}
data <- read.csv("../data/candidate-tweets.csv", stringsAsFactors=FALSE)
str(data)
head(data)
```

How many tweets are retweets? Create a new data frame that contains only original tweets (excluding retweets).

```{r}
length(grep('^RT @', data$text, ignore.case=TRUE))
tweets <- data[grepl('^RT @', data$text, ignore.case=TRUE)==FALSE,]
```

How many tweets were sent by each of the candidates? Create another (smaller) data frame that contains only tweets by Bernie Sanders.

```{r}
table(tweets$screen_name)
sanders <- tweets[tweets$screen_name=="BernieSanders",]
```

How many times did Bernie Sanders mention words related to 'health care'? and 'immigration'? and 'billionaires'? 'gun control'? 'poverty'? Use regular expressions to make sure your searches return all relevant results.

```{r}
length(grep('health', sanders$text, ignore.case=TRUE))
length(grep('immigr*', sanders$text, ignore.case=TRUE))
length(grep('guns', sanders$text, ignore.case=TRUE))
length(grep('minimum wage', sanders$text, ignore.case=TRUE))
length(grep('poverty', sanders$text, ignore.case=TRUE))
```

What are the 10 most frequent hashtags in the tweets by Bernie Sanders? Try to answer this question creating a function, instead of copying and pasting the code from earlier in the class.

```{r}
library(stringr)
top_hashtags <- function(text){
  hashtags <- str_extract_all(text, '#[A-Za-z0-9_]+')
  return(
    head(sort(table(unlist(hashtags)), decreasing = TRUE), n=10)
    )
}

top_hashtags(sanders$text)
```

Now, find the 10 most frequent hashtags for each candidate. You can use a loop to answer this question or just run the above function for each candidate separately.

```{r}
cands <- unique(tweets$screen_name)

for (cand in cands){
  message(cand)
  print(top_hashtags(tweets$text[tweets$screen_name==cand]))
}

```

Now going to back to the dataset with tweets by Bernie Sanders, try to create a corpus and DFM object. Think carefully through the different options (e.g. should you exclude stopwords?). Then, look at the 25 most frequent words.

```{r}
library(quanteda)
sanders_dfm <- dfm(corpus(sanders$text), remove=stopwords("english"),
                   remove_punct=TRUE, remove_url=TRUE)
topfeatures(sanders_dfm, n=25)
```

Plot the DFM you just created using a wordcloud. What do you learn?

```{r}
textplot_wordcloud(sanders_dfm, rot.per=0, scale=c(3, .75), max.words=50)
```

The variable `source` contains information about the device from which each tweet was sent. How many tweets did each candidate send from an Android device? and from an iphone? Use regular expressions applied to the `source` variable to answer this question.

```{r}
table(
  grepl('android', tweets$source, ignore.case = TRUE),
  tweets$screen_name
)

table(
  grepl('iphone', tweets$source, ignore.case = TRUE),
  tweets$screen_name
)

```
